For about five years, tremendous progress has been made in the speaker recognition field, especially for the speaker verification task in a phone environment. Supported by the evaluation campaigns organized by the National Institute of Standards and Technology (NIST)\cite{greenberg2013,greenberg2014}, this progress mainly relies on the development of the i-vector paradigm, which has definitely overtaken classical UBM/GMM \cite{bimbot2004}, or SVM \cite{wan2000} approaches. Inspired from the Joint Factor Analysis (JFA), which had already been applied with success in speaker detection, and which aims at estimating speaker and channel/session subspaces separately, the simpler and powerful i-vector-based modeling paradigm \cite{dehak2011} makes no distinction between the two subspaces thanks to a single total variability space, which covers both the speaker and session/channel variability. A large amount of studies has been dedicated to the enhancement of this paradigm by coupling it with different channel compensation techniques \cite{dehak2011,bousquet2012,kanagasundaram2014}, or by investigating various scoring approaches, which directly embed channel compensation~\cite{kenny2010,dehak2011,garcia2011,jiang2012,bousquet2014}. 

With regards to performance analysis, studies also mainly focus on speaker verification task.  In this framework, \cite{doddington98} have proposed a typology of speakers, using a menagerie lexicon, based on the observed properties of speakers to be more or less prone to miss detection or false alarm. Besides this typology, efforts have been made to identify and quantify the impact of the main factors that influence the performance of speaker verification. In~\cite{kahn10}, the authors report dramatic variations of performance, when varying the choice of the training session, for a similar amount of training data; similar trend is observed, on a lesser extent, for testing data.  \cite{BESTanalysis} investigate a range of variability factors, divided into "intrinsic" and "extrinsic" variations where "intrinsic" refers to internal speaker variability issues such as speech style and vocal efforts, and "extrinsic" refers to sources of variability external to the speaker, such as microphone, channels, noise. Their experiments show the strong impact of the variation of the speech style.
In the field of speaker diarization for conference meetings, \cite{Huijbregts07theblame} have  tried to identify the main factors contributing to errors, and to quantify their impact, through a set of oracle experiments. Their analysis showed that the speech detector, followed by the overlapped speech, were the main causes of errors.

Very few recent studies have concerned speaker identification in TV broadcast based on state-of-the-art speaker recognition systems. However, this context implies some non-trivial specificities such as the widely varying amount of training and testing data per speaker, the properties of speech segments - duration, number, acoustic quality, etc - implied in the identification decision while processing an entire TV show, generally issued from a preliminary speaker diarization step, and finally the coverage of speaker dictionary used by the system and its direct impact on an open-set identification task (closer to real life applications). In this paper, we propose to perform such a performance analysis, on the 3 systems submitted to the final round of the REPERE challenge~\cite{KAHN--CBMI--2012}, which has enabled the development of multimodal identification systems. Here, the analysis is restricted to the so-called "mono-modal" systems, which only use speaker voice to identify speakers. We are interested in analyzing the performance obtained individually for each speaker, and the influence of some of their characteristics (for instance in terms of speech turns duration, etc ) on the obtained performance. In Section~\ref{sec:protocol}, the corpus, the systems and the evaluation metrics are introduced. In Section~\ref{sec:analysis}, the performance analysis is done, and the influence of some features on the performance is investigated in Section~\ref{sec:prediction} through a performance prediction paradigm.