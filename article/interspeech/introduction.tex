For about five years, tremendous progress has been made in the speaker recognition field, especially for the speaker verification task in a phone environment. Supported by the evaluation campaigns organized by the National Institute of Standards and Technology (NIST)\cite{greenberg2013,greenberg2014}, this progress mainly relies on the development of the i-vector paradigm, which has definitely overtaken classical UBM/GMM \cite{bimbot2004}, or SVM \cite{wan2000} approaches. Inspired from the Joint Factor Analysis (JFA), which had already been applied with success in speaker detection, and which aims at estimating speaker and channel/session subspaces separately, the simpler and powerful i-vector-based modeling paradigm \cite{dehak2011} makes no distinction between both of subspaces thanks to a single total variability space, which covers both the speaker and session/channel variability. A large amount of studies has been dedicated to the enhancement of this paradigm, still in speaker verification, by coupling it with different channel compensation techniques\cite{dehak2011,bousquet2012,kanagasundaram2014}, or by investigating various scoring approaches, which directly embeds channel compensation\cite{kenny2010,dehak2011,garcia2011,jiang2012,bousquet2014}. 

When it comes to performance analysis, studies also mainly focus on speaker verification task.  In this framework, \cite{doddington98} have proposed a typology of speakers, using a menagerie lexicon, based on the observed properties of speakers to be more or less prone to miss detection or false alarm. Besides this typology, efforts have been made to identify the factors that may influence the performance of speaker verification. In \cite{kahn10}, the authors report dramatic variations of performance, when varying the choice of the training session, for a similar amount of training data; similar trend is observed, on a lesser extent, for testing data.  \cite{BESTanalysis} investigate a range of variabilities factors, divided in "intrinsic" variations and "extrinsic" variations where "intrinsic" refers to internal speaker variability issues such as speech style and vocal efforts, and "extrinsic" refers to sources of variability external to the speaker, such as microphone, channels, noise. Their experiments show, among others, the strong impact of the variation of the speech style.
In the field of speaker diarization, int the context of conference meetings, \cite{Huijbregts07theblame} have  tried to identify the main factors contributing to errors, and to quantify their impact, through a set of Oracle experiments. Their analysis showed that the speech analysis detector, followed by the overlapped speech, were the main causes of errors.

Very few recent studies  have concerned speaker identification in TV broadcast based on state-of-the-art speaker recognition systems. However, this context implies some non-trivial particularities such as the widely varying amount of training data and testing data per speaker, the properties of speech segments - duration, number, acoustic quality, etc - implied in the identification decision while processing an entire TV show, generally issued from a preliminary speaker diarization step, and finally the coverage of speaker dictionary used by the system and its direct impact on an open-set identification task (closer to real life applications). We propose in this paper to perform such performance analysis, on the 3 systems submitted to final round of the REPERE challenge \cite{KAHN--CBMI--2012}, which has enabled the development of multimodal identification systems. Here, the analysis is restricted to the so-called "mono-modal" systems, which only use speaker-voice to identify the speakers. We are interested in analyzing the performances obtained individually for each speaker, and the influence of some of their characteristics (for instance in terms of speech turns duration, etc ) on the obtained performance. In section \ref{sec:protocol}, the corpus, the systems and the evaluation measure are presented. In section \ref{sec:analysis}, the performance analysis is done, and the influence of some features on the performances are investigated in section \ref{sec:prediction} through a performance prediction paradigm.