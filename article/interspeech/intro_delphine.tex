
Error analysis have mainly been done in the context of speaker verification. In this framework, \cite{doddington98} have proposed a typology of speakers, using a menagerie lexicon, based on the observed properties of speakers to be more or less prone to miss detection or false alarm. Besides this typology, efforts have been made to identify the factors that may influence the performance of speaker verification. In \cite{kahn10}, the authors report dramatic variations of performance, when varying the choice of the training session, for a similar amount of training data; similar trend is observed, on a lesser extent, for testing data. They could not explain these variations with phonetic considerations, but they observed significant differences in the acoustic parameters. \cite{BESTanalysis} investigate a range of variabilities factors, divided in "intrinsic" variations and "extrinsic" variations where "intrinsic" refers to internal speaker variability issues such as speech style and vocal efforts, and "extrinsic" refers to sources of variability external to the speaker, such as microphone, channels, noise. Their experiments show, among other, the strong impact of the variation of the speech style.

In the field of speaker diarization, int the context of conference meetings, \cite{Huijbregts07theblame} have  tried to identify the main factors contributing to errors, and to quantify their impact, through a set of Oracle experiments. Their analysis showed that the speech analysis detector, followed by the overlapped speech, were the main causes of errors.

To our best knowledge, such error analysis have not yet been performed in the field of speaker identification in TV broadcast, which is a combination of speaker diarization and speaker recognition, for data which are different from the former ones (neither meetings, nor phone conversations).