The monomodal speaker ID system of PERCOL consortium relies on a typical i-vector framework. It is applied on each cluster provided by a speaker diarization system, which provides speech segments belonging to speakers as well as speaker clusters.
The diarization system is the one presented in \cite{charlet2013}. It is a sequential processing using firstly Bayesian Information Criterion and then Cross-likelihood Criterion. A special attention is paid for overlapped speech for TV-debates, where the amount of overlapped speech is significant. For these shows uniquely, overlapped speech segments are first detected and discarded from the clustering process, and then reassigned to the 2 nearest speakers, in terms of temporal distance between speech segments.

The i-vector-based speaker ID system relies on the ALIZE v3.0 toolkit \cite{larcher2013}. 19 LFCC augmented with their delta coefficients, the delta energy, and 11 double delta coefficients are used for the feature extraction. Features are then normalized, file by file, by applying a cepstral mean subtraction and variance normalization. The i-vector extraction relies on a 200 dimension total variability space estimated from about 1200 speakers and 7500 sessions. The Universal Background Model (UBM) is gender independent, represented by a 512 component Gaussian Mixture Model. It is learnt on about 200h of speech.

In the REPERE context, training data for a speaker may vary from a very few seconds to more than 2 hours. For this reason and based on the experience gained from the NIST evaluation campaigns, the extraction of the training i-vectors is carried out according to the following couple of rules : (1) for a given speaker, an i-vector is extracted only if a minimum 30s long training data are available, (2) if training data for a given speaker is longer than 2mn30, a set of i-vectors is extracted, each of them on the basis of 2mn30 duration, the last one having to respect the rule (1).
As mentioned above, a testing i-vector is extracted from all the speech segments gathered in a same cluster by the speaker diarization system. This cluster-based i-vector permits to handle overlap speech since a segment may be processed twice if it is attributed to different clusters during the speaker diarization process.

For the decision, the Cosine Distance Scoring (CDS) joined  with Within-Class covariance normalization for session/channel compensation is used to compare a couple of training and testing i-vectors. Matrix involved in the WCCN normalization is estimated on 571 speakers and 4384 sessions. When multiple training i-vectors are available to model a speaker, the maximum score is involved in the speaker ID decision process. Finally, all the scores are t-normed, notably for the open-set speaker identification task not discussed in this paper.


