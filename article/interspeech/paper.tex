\documentclass[a4paper]{article}

\usepackage{INTERSPEECH2015}

\usepackage{graphicx}
\usepackage{amssymb,amsmath,bm}
\usepackage{textcomp}
\usepackage{multirow}

\def\vec#1{\ensuremath{\bm{{#1}}}}
\def\mat#1{\vec{#1}}


\sloppy
\ninept


\title{What Makes a Speaker Recognizable in TV Broadcast?\\
Going Beyond Speaker Identification Error Rates}


% \title{Speakers identification in broadcast TV: facilities and barriers}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% If multiple authors, uncomment and edit the lines shown below.       %%
%% Note that each line must be emphasized {\em } by itself.             %%
%% (by Stephen Martucci, author of spconf.sty).                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\makeatletter
%\def\name#1{\gdef\@name{#1\\}}
%\makeatother
%\name{{\em Firstname1 Lastname1, Firstname2 Lastname2, Firstname3 Lastname3,}\\
%      {\em Firstname4 Lastname4, Firstname5 Lastname5, Firstname6 Lastname6,
%      Firstname7 Lastname7}}
%%%%%%%%%%%%%%% End of required multiple authors changes %%%%%%%%%%%%%%%%%

\makeatletter
\def\name#1{\gdef\@name{#1\\}}
\makeatother \name{{\em Delphine Charlet$^{1}$, Johann Poignant$^{2}$, Herv\'{e} Bredin$^{2}$, Corinne Fredouille$^{3}$, Sylvain Meignier$^{4}$}}

\address{$^1$ Orange Labs, Lannion, France\\
         $^2$ LIMSI -- CNRS -- Rue John Von Neumann, Orsay, France.\\
         $^3$ CERI/LIA - University of Avignon, France\\
         $^4$ LIUM \\
         {\small \tt delphine.charlet@orange.com}
}


\begin{document}

\maketitle

\begin{abstract}
Speaker identification approaches for TV broadcast are usually evaluated and compared based on global error rates derived from the overall duration of missed detection, false alarm and confusion.
Based on the analysis of the output of the systems submitted to the final round of the French evaluation campaign REPERE, this paper highlights the fact that these average metrics lead to the incorrect intuition that current state-of-the-art algorithms partially recognize all speakers. Setting aside incorrect diarization and adverse acoustic conditions, we show that their performance is in fact essentially bi-modal: either all speech turns of a speaker are correctly identified or none of them are. We then proceed with trying to understand and explain this behavior, through perfomance prediction experiments. These experiments show that the most discriminant speaker characteristics are -- first -- their total speech duration in the current show and -- then only -- the amount of training data available to build their acoustic model.
\end{abstract}

\noindent{\bf Index Terms}: speaker recognition, error analysis

\section{Introduction}
\label{sec:introduction}
\input{introduction}

\section{Experimental protocol}
\label{sec:protocol}
\input{protocol}

\section{Performance analysis}
\label{sec:analysis}
\input{analysis}

\section{Predicting speaker recognizability}
\label{sec:prediction}
\input{prediction}

\section{Cross-show extension}
\label{sec:xshow}
\input{xshow}

\section{Conclusions}
\label{sec:conclusion}
\input{conclusion}

\section{Acknowledgements}

\newpage
\eightpt

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
